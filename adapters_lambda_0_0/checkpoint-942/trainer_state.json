{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 942,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0,
      "loss_nll": 10.808700561523438,
      "loss_phi": 0.6487162113189697,
      "step": 0
    },
    {
      "epoch": 0,
      "loss_nll": 10.742116928100586,
      "loss_phi": 0.6627302169799805,
      "step": 0
    },
    {
      "epoch": 0.03189792663476874,
      "grad_norm": 28.08063507080078,
      "learning_rate": 0.0001980891719745223,
      "loss": 9.4666,
      "step": 10
    },
    {
      "epoch": 0.03189792663476874,
      "loss_nll": 2.720599889755249,
      "loss_phi": 1.37460458278656,
      "step": 10
    },
    {
      "epoch": 0.03189792663476874,
      "loss_nll": 2.5038537979125977,
      "loss_phi": 1.436585545539856,
      "step": 10
    },
    {
      "epoch": 0.06379585326953748,
      "grad_norm": 0.194207102060318,
      "learning_rate": 0.00019596602972399152,
      "loss": 0.7952,
      "step": 20
    },
    {
      "epoch": 0.06379585326953748,
      "loss_nll": 0.1514761745929718,
      "loss_phi": 0.7572923898696899,
      "step": 20
    },
    {
      "epoch": 0.06379585326953748,
      "loss_nll": 0.42479783296585083,
      "loss_phi": 0.7209903597831726,
      "step": 20
    },
    {
      "epoch": 0.09569377990430622,
      "grad_norm": 0.26362305879592896,
      "learning_rate": 0.00019384288747346072,
      "loss": 0.2321,
      "step": 30
    },
    {
      "epoch": 0.09569377990430622,
      "loss_nll": 0.16743141412734985,
      "loss_phi": 0.787182092666626,
      "step": 30
    },
    {
      "epoch": 0.09569377990430622,
      "loss_nll": 0.13785694539546967,
      "loss_phi": 0.8030600547790527,
      "step": 30
    },
    {
      "epoch": 0.12759170653907495,
      "grad_norm": 0.1562580168247223,
      "learning_rate": 0.00019171974522292994,
      "loss": 0.2097,
      "step": 40
    },
    {
      "epoch": 0.12759170653907495,
      "loss_nll": 0.3858400583267212,
      "loss_phi": 0.7640789151191711,
      "step": 40
    },
    {
      "epoch": 0.12759170653907495,
      "loss_nll": 0.1498568058013916,
      "loss_phi": 0.7695814967155457,
      "step": 40
    },
    {
      "epoch": 0.1594896331738437,
      "grad_norm": 0.14562377333641052,
      "learning_rate": 0.00018959660297239916,
      "loss": 0.2,
      "step": 50
    },
    {
      "epoch": 0.1594896331738437,
      "loss_nll": 0.3179241716861725,
      "loss_phi": 0.7390020489692688,
      "step": 50
    },
    {
      "epoch": 0.1594896331738437,
      "loss_nll": 0.1866222321987152,
      "loss_phi": 0.7658565044403076,
      "step": 50
    },
    {
      "epoch": 0.19138755980861244,
      "grad_norm": 0.12827306985855103,
      "learning_rate": 0.00018747346072186838,
      "loss": 0.1787,
      "step": 60
    },
    {
      "epoch": 0.19138755980861244,
      "loss_nll": 0.4467284679412842,
      "loss_phi": 0.715237021446228,
      "step": 60
    },
    {
      "epoch": 0.19138755980861244,
      "loss_nll": 0.19801530241966248,
      "loss_phi": 0.7420855164527893,
      "step": 60
    },
    {
      "epoch": 0.22328548644338117,
      "grad_norm": 0.12065152078866959,
      "learning_rate": 0.0001853503184713376,
      "loss": 0.2466,
      "step": 70
    },
    {
      "epoch": 0.22328548644338117,
      "loss_nll": 0.17285336554050446,
      "loss_phi": 0.7308071255683899,
      "step": 70
    },
    {
      "epoch": 0.22328548644338117,
      "loss_nll": 1.3103289604187012,
      "loss_phi": 0.6637372970581055,
      "step": 70
    },
    {
      "epoch": 0.2551834130781499,
      "grad_norm": 0.178571879863739,
      "learning_rate": 0.0001832271762208068,
      "loss": 0.2748,
      "step": 80
    },
    {
      "epoch": 0.2551834130781499,
      "loss_nll": 0.25496676564216614,
      "loss_phi": 0.7395704984664917,
      "step": 80
    },
    {
      "epoch": 0.2551834130781499,
      "loss_nll": 0.17823021113872528,
      "loss_phi": 0.746060311794281,
      "step": 80
    },
    {
      "epoch": 0.28708133971291866,
      "grad_norm": 0.16763338446617126,
      "learning_rate": 0.00018110403397027602,
      "loss": 0.1762,
      "step": 90
    },
    {
      "epoch": 0.28708133971291866,
      "loss_nll": 0.21845662593841553,
      "loss_phi": 0.7334336042404175,
      "step": 90
    },
    {
      "epoch": 0.28708133971291866,
      "loss_nll": 0.326570063829422,
      "loss_phi": 0.767210841178894,
      "step": 90
    },
    {
      "epoch": 0.3189792663476874,
      "grad_norm": 0.17228879034519196,
      "learning_rate": 0.00017898089171974524,
      "loss": 0.1885,
      "step": 100
    },
    {
      "epoch": 0.3189792663476874,
      "loss_nll": 0.617048442363739,
      "loss_phi": 0.7698190212249756,
      "step": 100
    },
    {
      "epoch": 0.3189792663476874,
      "loss_nll": 0.23909372091293335,
      "loss_phi": 0.7762323617935181,
      "step": 100
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.08443082123994827,
      "learning_rate": 0.00017685774946921446,
      "loss": 0.1605,
      "step": 110
    },
    {
      "epoch": 0.3508771929824561,
      "loss_nll": 0.10018111765384674,
      "loss_phi": 0.8063313961029053,
      "step": 110
    },
    {
      "epoch": 0.3508771929824561,
      "loss_nll": 0.08156679570674896,
      "loss_phi": 0.8220557570457458,
      "step": 110
    },
    {
      "epoch": 0.3827751196172249,
      "grad_norm": 0.10031794756650925,
      "learning_rate": 0.00017473460721868366,
      "loss": 0.1986,
      "step": 120
    },
    {
      "epoch": 0.3827751196172249,
      "loss_nll": 0.21857453882694244,
      "loss_phi": 0.7862492203712463,
      "step": 120
    },
    {
      "epoch": 0.3827751196172249,
      "loss_nll": 0.12961649894714355,
      "loss_phi": 0.8087995648384094,
      "step": 120
    },
    {
      "epoch": 0.41467304625199364,
      "grad_norm": 0.09967644512653351,
      "learning_rate": 0.00017261146496815288,
      "loss": 0.1783,
      "step": 130
    },
    {
      "epoch": 0.41467304625199364,
      "loss_nll": 0.2455701380968094,
      "loss_phi": 0.7806245684623718,
      "step": 130
    },
    {
      "epoch": 0.41467304625199364,
      "loss_nll": 0.0974080041050911,
      "loss_phi": 0.8096339106559753,
      "step": 130
    },
    {
      "epoch": 0.44657097288676234,
      "grad_norm": 0.11234539747238159,
      "learning_rate": 0.0001704883227176221,
      "loss": 0.1956,
      "step": 140
    },
    {
      "epoch": 0.44657097288676234,
      "loss_nll": 0.10664516687393188,
      "loss_phi": 0.8200146555900574,
      "step": 140
    },
    {
      "epoch": 0.44657097288676234,
      "loss_nll": 0.24267996847629547,
      "loss_phi": 0.7875090837478638,
      "step": 140
    },
    {
      "epoch": 0.4784688995215311,
      "grad_norm": 0.1168106198310852,
      "learning_rate": 0.00016836518046709132,
      "loss": 0.2041,
      "step": 150
    },
    {
      "epoch": 0.4784688995215311,
      "loss_nll": 0.13609878718852997,
      "loss_phi": 0.8296263217926025,
      "step": 150
    },
    {
      "epoch": 0.4784688995215311,
      "loss_nll": 0.2965090274810791,
      "loss_phi": 0.8145728707313538,
      "step": 150
    },
    {
      "epoch": 0.5103668261562998,
      "grad_norm": 0.11596345156431198,
      "learning_rate": 0.00016624203821656052,
      "loss": 0.1868,
      "step": 160
    },
    {
      "epoch": 0.5103668261562998,
      "loss_nll": 0.1254463940858841,
      "loss_phi": 0.8481245040893555,
      "step": 160
    },
    {
      "epoch": 0.5103668261562998,
      "loss_nll": 0.2105049192905426,
      "loss_phi": 0.8366210460662842,
      "step": 160
    },
    {
      "epoch": 0.5422647527910686,
      "grad_norm": 0.22156290709972382,
      "learning_rate": 0.00016411889596602974,
      "loss": 0.1527,
      "step": 170
    },
    {
      "epoch": 0.5422647527910686,
      "loss_nll": 0.2798381745815277,
      "loss_phi": 0.8254292607307434,
      "step": 170
    },
    {
      "epoch": 0.5422647527910686,
      "loss_nll": 0.17082232236862183,
      "loss_phi": 0.8455524444580078,
      "step": 170
    },
    {
      "epoch": 0.5741626794258373,
      "grad_norm": 0.09991440176963806,
      "learning_rate": 0.00016199575371549896,
      "loss": 0.1825,
      "step": 180
    },
    {
      "epoch": 0.5741626794258373,
      "loss_nll": 0.12219855189323425,
      "loss_phi": 0.8368667960166931,
      "step": 180
    },
    {
      "epoch": 0.5741626794258373,
      "loss_nll": 0.15032678842544556,
      "loss_phi": 0.8305685520172119,
      "step": 180
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 0.2664113938808441,
      "learning_rate": 0.00015987261146496818,
      "loss": 0.1927,
      "step": 190
    },
    {
      "epoch": 0.6060606060606061,
      "loss_nll": 0.17942717671394348,
      "loss_phi": 0.8508134484291077,
      "step": 190
    },
    {
      "epoch": 0.6060606060606061,
      "loss_nll": 0.7520633339881897,
      "loss_phi": 0.7671253681182861,
      "step": 190
    },
    {
      "epoch": 0.6379585326953748,
      "grad_norm": 0.0906132310628891,
      "learning_rate": 0.00015774946921443737,
      "loss": 0.1941,
      "step": 200
    },
    {
      "epoch": 0.6379585326953748,
      "loss_nll": 0.17645490169525146,
      "loss_phi": 0.8451724648475647,
      "step": 200
    },
    {
      "epoch": 0.6379585326953748,
      "loss_nll": 0.13028742372989655,
      "loss_phi": 0.8514065146446228,
      "step": 200
    },
    {
      "epoch": 0.6698564593301436,
      "grad_norm": 0.2470761090517044,
      "learning_rate": 0.0001556263269639066,
      "loss": 0.1928,
      "step": 210
    },
    {
      "epoch": 0.6698564593301436,
      "loss_nll": 0.2273246794939041,
      "loss_phi": 0.8662674427032471,
      "step": 210
    },
    {
      "epoch": 0.6698564593301436,
      "loss_nll": 0.060652345418930054,
      "loss_phi": 0.857589840888977,
      "step": 210
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.13569119572639465,
      "learning_rate": 0.00015350318471337582,
      "loss": 0.1843,
      "step": 220
    },
    {
      "epoch": 0.7017543859649122,
      "loss_nll": 0.18647103011608124,
      "loss_phi": 0.8614968657493591,
      "step": 220
    },
    {
      "epoch": 0.7017543859649122,
      "loss_nll": 0.7360398173332214,
      "loss_phi": 0.79609215259552,
      "step": 220
    },
    {
      "epoch": 0.733652312599681,
      "grad_norm": 0.1439184993505478,
      "learning_rate": 0.00015138004246284504,
      "loss": 0.255,
      "step": 230
    },
    {
      "epoch": 0.733652312599681,
      "loss_nll": 0.1495232880115509,
      "loss_phi": 0.8689184188842773,
      "step": 230
    },
    {
      "epoch": 0.733652312599681,
      "loss_nll": 0.10720354318618774,
      "loss_phi": 0.874816358089447,
      "step": 230
    },
    {
      "epoch": 0.7655502392344498,
      "grad_norm": 0.14538688957691193,
      "learning_rate": 0.00014925690021231423,
      "loss": 0.1782,
      "step": 240
    },
    {
      "epoch": 0.7655502392344498,
      "loss_nll": 0.14682988822460175,
      "loss_phi": 0.8947947025299072,
      "step": 240
    },
    {
      "epoch": 0.7655502392344498,
      "loss_nll": 0.11227154731750488,
      "loss_phi": 0.9001619815826416,
      "step": 240
    },
    {
      "epoch": 0.7974481658692185,
      "grad_norm": 0.13068340718746185,
      "learning_rate": 0.00014713375796178343,
      "loss": 0.1596,
      "step": 250
    },
    {
      "epoch": 0.7974481658692185,
      "loss_nll": 0.20835067331790924,
      "loss_phi": 0.8921992182731628,
      "step": 250
    },
    {
      "epoch": 0.7974481658692185,
      "loss_nll": 0.16937196254730225,
      "loss_phi": 0.9101194143295288,
      "step": 250
    },
    {
      "epoch": 0.8293460925039873,
      "grad_norm": 0.11087094247341156,
      "learning_rate": 0.00014501061571125265,
      "loss": 0.2332,
      "step": 260
    },
    {
      "epoch": 0.8293460925039873,
      "loss_nll": 0.08658458292484283,
      "loss_phi": 0.9115540981292725,
      "step": 260
    },
    {
      "epoch": 0.8293460925039873,
      "loss_nll": 0.4286443591117859,
      "loss_phi": 0.8513653874397278,
      "step": 260
    },
    {
      "epoch": 0.861244019138756,
      "grad_norm": 0.10842572897672653,
      "learning_rate": 0.00014288747346072187,
      "loss": 0.2002,
      "step": 270
    },
    {
      "epoch": 0.861244019138756,
      "loss_nll": 0.12277328968048096,
      "loss_phi": 0.9113991856575012,
      "step": 270
    },
    {
      "epoch": 0.861244019138756,
      "loss_nll": 0.06710612028837204,
      "loss_phi": 0.9205551743507385,
      "step": 270
    },
    {
      "epoch": 0.8931419457735247,
      "grad_norm": 0.09004785120487213,
      "learning_rate": 0.0001407643312101911,
      "loss": 0.1883,
      "step": 280
    },
    {
      "epoch": 0.8931419457735247,
      "loss_nll": 0.15219806134700775,
      "loss_phi": 0.9104117155075073,
      "step": 280
    },
    {
      "epoch": 0.8931419457735247,
      "loss_nll": 0.08298785239458084,
      "loss_phi": 0.9419856071472168,
      "step": 280
    },
    {
      "epoch": 0.9250398724082934,
      "grad_norm": 0.16891537606716156,
      "learning_rate": 0.00013864118895966029,
      "loss": 0.1922,
      "step": 290
    },
    {
      "epoch": 0.9250398724082934,
      "loss_nll": 0.0669475793838501,
      "loss_phi": 0.958117663860321,
      "step": 290
    },
    {
      "epoch": 0.9250398724082934,
      "loss_nll": 1.0359065532684326,
      "loss_phi": 0.8099314570426941,
      "step": 290
    },
    {
      "epoch": 0.9569377990430622,
      "grad_norm": 0.0813242718577385,
      "learning_rate": 0.0001365180467091295,
      "loss": 0.2079,
      "step": 300
    },
    {
      "epoch": 0.9569377990430622,
      "loss_nll": 0.07846184819936752,
      "loss_phi": 0.9125208854675293,
      "step": 300
    },
    {
      "epoch": 0.9569377990430622,
      "loss_nll": 0.1357584148645401,
      "loss_phi": 0.8847312331199646,
      "step": 300
    },
    {
      "epoch": 0.988835725677831,
      "grad_norm": 0.15659628808498383,
      "learning_rate": 0.00013439490445859873,
      "loss": 0.1689,
      "step": 310
    },
    {
      "epoch": 0.988835725677831,
      "loss_nll": 0.4542628228664398,
      "loss_phi": 0.8755845427513123,
      "step": 310
    },
    {
      "epoch": 0.988835725677831,
      "loss_nll": 0.1432798206806183,
      "loss_phi": 0.892400860786438,
      "step": 310
    },
    {
      "epoch": 1.0191387559808613,
      "grad_norm": 0.09681388735771179,
      "learning_rate": 0.00013227176220806795,
      "loss": 0.2432,
      "step": 320
    },
    {
      "epoch": 1.0191387559808613,
      "loss_nll": 0.17207130789756775,
      "loss_phi": 0.866628110408783,
      "step": 320
    },
    {
      "epoch": 1.0191387559808613,
      "loss_nll": 0.21370188891887665,
      "loss_phi": 0.8843221664428711,
      "step": 320
    },
    {
      "epoch": 1.0510366826156299,
      "grad_norm": 0.14774389564990997,
      "learning_rate": 0.00013014861995753714,
      "loss": 0.2043,
      "step": 330
    },
    {
      "epoch": 1.0510366826156299,
      "loss_nll": 0.24537459015846252,
      "loss_phi": 0.8724808096885681,
      "step": 330
    },
    {
      "epoch": 1.0510366826156299,
      "loss_nll": 0.07879865914583206,
      "loss_phi": 0.9131184220314026,
      "step": 330
    },
    {
      "epoch": 1.0829346092503986,
      "grad_norm": 0.1276455670595169,
      "learning_rate": 0.00012802547770700637,
      "loss": 0.1602,
      "step": 340
    },
    {
      "epoch": 1.0829346092503986,
      "loss_nll": 0.17920450866222382,
      "loss_phi": 0.8708730340003967,
      "step": 340
    },
    {
      "epoch": 1.0829346092503986,
      "loss_nll": 0.08992837369441986,
      "loss_phi": 0.9244045615196228,
      "step": 340
    },
    {
      "epoch": 1.1148325358851674,
      "grad_norm": 0.1270705908536911,
      "learning_rate": 0.0001259023354564756,
      "loss": 0.1839,
      "step": 350
    },
    {
      "epoch": 1.1148325358851674,
      "loss_nll": 0.21000969409942627,
      "loss_phi": 0.8863369822502136,
      "step": 350
    },
    {
      "epoch": 1.1148325358851674,
      "loss_nll": 0.1376953125,
      "loss_phi": 0.8995702862739563,
      "step": 350
    },
    {
      "epoch": 1.1467304625199362,
      "grad_norm": 0.10082706809043884,
      "learning_rate": 0.0001237791932059448,
      "loss": 0.206,
      "step": 360
    },
    {
      "epoch": 1.1467304625199362,
      "loss_nll": 0.11698930710554123,
      "loss_phi": 0.9235067963600159,
      "step": 360
    },
    {
      "epoch": 1.1467304625199362,
      "loss_nll": 0.12434802204370499,
      "loss_phi": 0.9165676236152649,
      "step": 360
    },
    {
      "epoch": 1.178628389154705,
      "grad_norm": 0.10052314400672913,
      "learning_rate": 0.00012165605095541402,
      "loss": 0.1821,
      "step": 370
    },
    {
      "epoch": 1.178628389154705,
      "loss_nll": 0.30320388078689575,
      "loss_phi": 0.8635985851287842,
      "step": 370
    },
    {
      "epoch": 1.178628389154705,
      "loss_nll": 0.087426096200943,
      "loss_phi": 0.9195497035980225,
      "step": 370
    },
    {
      "epoch": 1.2105263157894737,
      "grad_norm": 0.086951844394207,
      "learning_rate": 0.00011953290870488322,
      "loss": 0.2163,
      "step": 380
    },
    {
      "epoch": 1.2105263157894737,
      "loss_nll": 0.190107524394989,
      "loss_phi": 0.8757569193840027,
      "step": 380
    },
    {
      "epoch": 1.2105263157894737,
      "loss_nll": 0.3288576900959015,
      "loss_phi": 0.8490412831306458,
      "step": 380
    },
    {
      "epoch": 1.2424242424242424,
      "grad_norm": 0.10947724431753159,
      "learning_rate": 0.00011740976645435245,
      "loss": 0.1879,
      "step": 390
    },
    {
      "epoch": 1.2424242424242424,
      "loss_nll": 0.09728062152862549,
      "loss_phi": 0.9298111200332642,
      "step": 390
    },
    {
      "epoch": 1.2424242424242424,
      "loss_nll": 0.0791739895939827,
      "loss_phi": 0.9070656895637512,
      "step": 390
    },
    {
      "epoch": 1.2743221690590112,
      "grad_norm": 0.19410553574562073,
      "learning_rate": 0.00011528662420382165,
      "loss": 0.2442,
      "step": 400
    },
    {
      "epoch": 1.2743221690590112,
      "loss_nll": 0.24545074999332428,
      "loss_phi": 0.8589752912521362,
      "step": 400
    },
    {
      "epoch": 1.2743221690590112,
      "loss_nll": 0.10856705158948898,
      "loss_phi": 0.9098759293556213,
      "step": 400
    },
    {
      "epoch": 1.30622009569378,
      "grad_norm": 0.12012659013271332,
      "learning_rate": 0.00011316348195329088,
      "loss": 0.1818,
      "step": 410
    },
    {
      "epoch": 1.30622009569378,
      "loss_nll": 0.6970430612564087,
      "loss_phi": 0.850292444229126,
      "step": 410
    },
    {
      "epoch": 1.30622009569378,
      "loss_nll": 0.7490484118461609,
      "loss_phi": 0.855429470539093,
      "step": 410
    },
    {
      "epoch": 1.3381180223285487,
      "grad_norm": 0.13530313968658447,
      "learning_rate": 0.00011104033970276008,
      "loss": 0.2358,
      "step": 420
    },
    {
      "epoch": 1.3381180223285487,
      "loss_nll": 0.13984344899654388,
      "loss_phi": 0.8798052668571472,
      "step": 420
    },
    {
      "epoch": 1.3381180223285487,
      "loss_nll": 0.26350536942481995,
      "loss_phi": 0.8927325010299683,
      "step": 420
    },
    {
      "epoch": 1.3700159489633175,
      "grad_norm": 0.12002824246883392,
      "learning_rate": 0.0001089171974522293,
      "loss": 0.1526,
      "step": 430
    },
    {
      "epoch": 1.3700159489633175,
      "loss_nll": 0.08920230716466904,
      "loss_phi": 0.8889291882514954,
      "step": 430
    },
    {
      "epoch": 1.3700159489633175,
      "loss_nll": 0.11580220609903336,
      "loss_phi": 0.8810025453567505,
      "step": 430
    },
    {
      "epoch": 1.401913875598086,
      "grad_norm": 0.09595569968223572,
      "learning_rate": 0.00010679405520169851,
      "loss": 0.1528,
      "step": 440
    },
    {
      "epoch": 1.401913875598086,
      "loss_nll": 0.3028004467487335,
      "loss_phi": 0.8644437193870544,
      "step": 440
    },
    {
      "epoch": 1.401913875598086,
      "loss_nll": 0.1618187427520752,
      "loss_phi": 0.888277530670166,
      "step": 440
    },
    {
      "epoch": 1.4338118022328548,
      "grad_norm": 0.11820270121097565,
      "learning_rate": 0.00010467091295116773,
      "loss": 0.1541,
      "step": 450
    },
    {
      "epoch": 1.4338118022328548,
      "loss_nll": 0.1128934696316719,
      "loss_phi": 0.9025892615318298,
      "step": 450
    },
    {
      "epoch": 1.4338118022328548,
      "loss_nll": 0.08102896809577942,
      "loss_phi": 0.9046285152435303,
      "step": 450
    },
    {
      "epoch": 1.4657097288676235,
      "grad_norm": 0.23637047410011292,
      "learning_rate": 0.00010254777070063694,
      "loss": 0.1945,
      "step": 460
    },
    {
      "epoch": 1.4657097288676235,
      "loss_nll": 0.2621864974498749,
      "loss_phi": 0.8750171661376953,
      "step": 460
    },
    {
      "epoch": 1.4657097288676235,
      "loss_nll": 0.14026691019535065,
      "loss_phi": 0.9197640419006348,
      "step": 460
    },
    {
      "epoch": 1.4976076555023923,
      "grad_norm": 0.14527903497219086,
      "learning_rate": 0.00010042462845010616,
      "loss": 0.2478,
      "step": 470
    },
    {
      "epoch": 1.4976076555023923,
      "loss_nll": 0.23326976597309113,
      "loss_phi": 0.9025905728340149,
      "step": 470
    },
    {
      "epoch": 1.4976076555023923,
      "loss_nll": 0.09685070067644119,
      "loss_phi": 0.9217519164085388,
      "step": 470
    },
    {
      "epoch": 1.529505582137161,
      "grad_norm": 0.11758971959352493,
      "learning_rate": 9.830148619957537e-05,
      "loss": 0.1912,
      "step": 480
    },
    {
      "epoch": 1.529505582137161,
      "loss_nll": 0.11770422011613846,
      "loss_phi": 0.8983247876167297,
      "step": 480
    },
    {
      "epoch": 1.529505582137161,
      "loss_nll": 0.1540045440196991,
      "loss_phi": 0.8986915946006775,
      "step": 480
    },
    {
      "epoch": 1.5614035087719298,
      "grad_norm": 0.15657232701778412,
      "learning_rate": 9.617834394904459e-05,
      "loss": 0.1753,
      "step": 490
    },
    {
      "epoch": 1.5614035087719298,
      "loss_nll": 0.08652830123901367,
      "loss_phi": 0.9125277400016785,
      "step": 490
    },
    {
      "epoch": 1.5614035087719298,
      "loss_nll": 0.2346920371055603,
      "loss_phi": 0.8859001994132996,
      "step": 490
    },
    {
      "epoch": 1.5933014354066986,
      "grad_norm": 0.11748173087835312,
      "learning_rate": 9.40552016985138e-05,
      "loss": 0.1508,
      "step": 500
    },
    {
      "epoch": 1.5933014354066986,
      "loss_nll": 0.16136059165000916,
      "loss_phi": 0.9126737117767334,
      "step": 500
    },
    {
      "epoch": 1.5933014354066986,
      "loss_nll": 0.12099718302488327,
      "loss_phi": 0.9158127903938293,
      "step": 500
    },
    {
      "epoch": 1.6251993620414673,
      "grad_norm": 0.0848376452922821,
      "learning_rate": 9.193205944798302e-05,
      "loss": 0.1692,
      "step": 510
    },
    {
      "epoch": 1.6251993620414673,
      "loss_nll": 0.1256292313337326,
      "loss_phi": 0.9198020100593567,
      "step": 510
    },
    {
      "epoch": 1.6251993620414673,
      "loss_nll": 0.29186928272247314,
      "loss_phi": 0.8805421590805054,
      "step": 510
    },
    {
      "epoch": 1.657097288676236,
      "grad_norm": 0.11400764435529709,
      "learning_rate": 8.980891719745223e-05,
      "loss": 0.1836,
      "step": 520
    },
    {
      "epoch": 1.657097288676236,
      "loss_nll": 0.28864333033561707,
      "loss_phi": 0.8868210911750793,
      "step": 520
    },
    {
      "epoch": 1.657097288676236,
      "loss_nll": 0.115177221596241,
      "loss_phi": 0.9280228018760681,
      "step": 520
    },
    {
      "epoch": 1.6889952153110048,
      "grad_norm": 0.11653151363134384,
      "learning_rate": 8.768577494692145e-05,
      "loss": 0.1567,
      "step": 530
    },
    {
      "epoch": 1.6889952153110048,
      "loss_nll": 0.4548773467540741,
      "loss_phi": 0.8717507719993591,
      "step": 530
    },
    {
      "epoch": 1.6889952153110048,
      "loss_nll": 0.10146509110927582,
      "loss_phi": 0.9151886701583862,
      "step": 530
    },
    {
      "epoch": 1.7208931419457736,
      "grad_norm": 0.14499053359031677,
      "learning_rate": 8.556263269639066e-05,
      "loss": 0.2451,
      "step": 540
    },
    {
      "epoch": 1.7208931419457736,
      "loss_nll": 0.4671057164669037,
      "loss_phi": 0.8572935461997986,
      "step": 540
    },
    {
      "epoch": 1.7208931419457736,
      "loss_nll": 0.10788653790950775,
      "loss_phi": 0.925592839717865,
      "step": 540
    },
    {
      "epoch": 1.7527910685805423,
      "grad_norm": 0.1212950125336647,
      "learning_rate": 8.343949044585988e-05,
      "loss": 0.1902,
      "step": 550
    },
    {
      "epoch": 1.7527910685805423,
      "loss_nll": 0.24493835866451263,
      "loss_phi": 0.9047495722770691,
      "step": 550
    },
    {
      "epoch": 1.7527910685805423,
      "loss_nll": 0.13713321089744568,
      "loss_phi": 0.8991075754165649,
      "step": 550
    },
    {
      "epoch": 1.784688995215311,
      "grad_norm": 0.12321672588586807,
      "learning_rate": 8.13163481953291e-05,
      "loss": 0.2046,
      "step": 560
    },
    {
      "epoch": 1.784688995215311,
      "loss_nll": 0.12773379683494568,
      "loss_phi": 0.9245945811271667,
      "step": 560
    },
    {
      "epoch": 1.784688995215311,
      "loss_nll": 0.08206751197576523,
      "loss_phi": 0.9409658908843994,
      "step": 560
    },
    {
      "epoch": 1.8165869218500799,
      "grad_norm": 0.15820923447608948,
      "learning_rate": 7.919320594479831e-05,
      "loss": 0.1719,
      "step": 570
    },
    {
      "epoch": 1.8165869218500799,
      "loss_nll": 0.1674768328666687,
      "loss_phi": 0.9106186032295227,
      "step": 570
    },
    {
      "epoch": 1.8165869218500799,
      "loss_nll": 0.07372523099184036,
      "loss_phi": 0.921167254447937,
      "step": 570
    },
    {
      "epoch": 1.8484848484848486,
      "grad_norm": 0.11535623669624329,
      "learning_rate": 7.707006369426753e-05,
      "loss": 0.1729,
      "step": 580
    },
    {
      "epoch": 1.8484848484848486,
      "loss_nll": 0.07876478135585785,
      "loss_phi": 0.9176192879676819,
      "step": 580
    },
    {
      "epoch": 1.8484848484848486,
      "loss_nll": 0.06592752784490585,
      "loss_phi": 0.9217864274978638,
      "step": 580
    },
    {
      "epoch": 1.8803827751196174,
      "grad_norm": 0.11498551815748215,
      "learning_rate": 7.494692144373673e-05,
      "loss": 0.2383,
      "step": 590
    },
    {
      "epoch": 1.8803827751196174,
      "loss_nll": 0.10593927651643753,
      "loss_phi": 0.9237633347511292,
      "step": 590
    },
    {
      "epoch": 1.8803827751196174,
      "loss_nll": 0.20722238719463348,
      "loss_phi": 0.9165406823158264,
      "step": 590
    },
    {
      "epoch": 1.912280701754386,
      "grad_norm": 0.09646902978420258,
      "learning_rate": 7.282377919320595e-05,
      "loss": 0.1344,
      "step": 600
    },
    {
      "epoch": 1.912280701754386,
      "loss_nll": 0.1855524778366089,
      "loss_phi": 0.8933931589126587,
      "step": 600
    },
    {
      "epoch": 1.912280701754386,
      "loss_nll": 0.2045261561870575,
      "loss_phi": 0.8832347393035889,
      "step": 600
    },
    {
      "epoch": 1.9441786283891547,
      "grad_norm": 0.10495219379663467,
      "learning_rate": 7.070063694267515e-05,
      "loss": 0.2332,
      "step": 610
    },
    {
      "epoch": 1.9441786283891547,
      "loss_nll": 0.11703634262084961,
      "loss_phi": 0.9012259244918823,
      "step": 610
    },
    {
      "epoch": 1.9441786283891547,
      "loss_nll": 0.10085991770029068,
      "loss_phi": 0.9126797914505005,
      "step": 610
    },
    {
      "epoch": 1.9760765550239234,
      "grad_norm": 0.09992560744285583,
      "learning_rate": 6.857749469214438e-05,
      "loss": 0.1576,
      "step": 620
    },
    {
      "epoch": 1.9760765550239234,
      "loss_nll": 0.05191737413406372,
      "loss_phi": 0.8946527242660522,
      "step": 620
    },
    {
      "epoch": 1.9760765550239234,
      "loss_nll": 0.13564424216747284,
      "loss_phi": 0.8935481905937195,
      "step": 620
    },
    {
      "epoch": 2.006379585326954,
      "grad_norm": 0.11594931036233902,
      "learning_rate": 6.645435244161358e-05,
      "loss": 0.133,
      "step": 630
    },
    {
      "epoch": 2.006379585326954,
      "loss_nll": 0.06721597909927368,
      "loss_phi": 0.9045172333717346,
      "step": 630
    },
    {
      "epoch": 2.006379585326954,
      "loss_nll": 0.3710270822048187,
      "loss_phi": 0.8621811270713806,
      "step": 630
    },
    {
      "epoch": 2.0382775119617227,
      "grad_norm": 0.10780219733715057,
      "learning_rate": 6.43312101910828e-05,
      "loss": 0.1588,
      "step": 640
    },
    {
      "epoch": 2.0382775119617227,
      "loss_nll": 0.5213435292243958,
      "loss_phi": 0.8426894545555115,
      "step": 640
    },
    {
      "epoch": 2.0382775119617227,
      "loss_nll": 0.11716365069150925,
      "loss_phi": 0.9070771336555481,
      "step": 640
    },
    {
      "epoch": 2.0701754385964914,
      "grad_norm": 0.09175323694944382,
      "learning_rate": 6.220806794055201e-05,
      "loss": 0.1808,
      "step": 650
    },
    {
      "epoch": 2.0701754385964914,
      "loss_nll": 0.1060878336429596,
      "loss_phi": 0.9067777991294861,
      "step": 650
    },
    {
      "epoch": 2.0701754385964914,
      "loss_nll": 0.10063651204109192,
      "loss_phi": 0.9067912101745605,
      "step": 650
    },
    {
      "epoch": 2.1020733652312598,
      "grad_norm": 0.1420242339372635,
      "learning_rate": 6.0084925690021235e-05,
      "loss": 0.2455,
      "step": 660
    },
    {
      "epoch": 2.1020733652312598,
      "loss_nll": 0.18453481793403625,
      "loss_phi": 0.8968327641487122,
      "step": 660
    },
    {
      "epoch": 2.1020733652312598,
      "loss_nll": 0.0719723030924797,
      "loss_phi": 0.909875750541687,
      "step": 660
    },
    {
      "epoch": 2.1339712918660285,
      "grad_norm": 0.0989418774843216,
      "learning_rate": 5.796178343949045e-05,
      "loss": 0.1722,
      "step": 670
    },
    {
      "epoch": 2.1339712918660285,
      "loss_nll": 0.06899519264698029,
      "loss_phi": 0.8964301347732544,
      "step": 670
    },
    {
      "epoch": 2.1339712918660285,
      "loss_nll": 0.3061971962451935,
      "loss_phi": 0.8597264289855957,
      "step": 670
    },
    {
      "epoch": 2.1658692185007973,
      "grad_norm": 0.12328287214040756,
      "learning_rate": 5.5838641188959664e-05,
      "loss": 0.246,
      "step": 680
    },
    {
      "epoch": 2.1658692185007973,
      "loss_nll": 0.16047362983226776,
      "loss_phi": 0.8792017102241516,
      "step": 680
    },
    {
      "epoch": 2.1658692185007973,
      "loss_nll": 0.2085411250591278,
      "loss_phi": 0.8762643337249756,
      "step": 680
    },
    {
      "epoch": 2.197767145135566,
      "grad_norm": 0.12351657450199127,
      "learning_rate": 5.371549893842888e-05,
      "loss": 0.1953,
      "step": 690
    },
    {
      "epoch": 2.197767145135566,
      "loss_nll": 0.0924236923456192,
      "loss_phi": 0.9100554585456848,
      "step": 690
    },
    {
      "epoch": 2.197767145135566,
      "loss_nll": 0.09117119014263153,
      "loss_phi": 0.8899559378623962,
      "step": 690
    },
    {
      "epoch": 2.229665071770335,
      "grad_norm": 0.12776052951812744,
      "learning_rate": 5.159235668789809e-05,
      "loss": 0.1584,
      "step": 700
    },
    {
      "epoch": 2.229665071770335,
      "loss_nll": 0.346636027097702,
      "loss_phi": 0.8711652159690857,
      "step": 700
    },
    {
      "epoch": 2.229665071770335,
      "loss_nll": 0.10124974697828293,
      "loss_phi": 0.8942914009094238,
      "step": 700
    },
    {
      "epoch": 2.2615629984051036,
      "grad_norm": 0.09976257383823395,
      "learning_rate": 4.946921443736731e-05,
      "loss": 0.1825,
      "step": 710
    },
    {
      "epoch": 2.2615629984051036,
      "loss_nll": 0.1627734750509262,
      "loss_phi": 0.897919774055481,
      "step": 710
    },
    {
      "epoch": 2.2615629984051036,
      "loss_nll": 0.11454761773347855,
      "loss_phi": 0.8940345644950867,
      "step": 710
    },
    {
      "epoch": 2.2934609250398723,
      "grad_norm": 0.14286790788173676,
      "learning_rate": 4.734607218683652e-05,
      "loss": 0.1652,
      "step": 720
    },
    {
      "epoch": 2.2934609250398723,
      "loss_nll": 0.27760428190231323,
      "loss_phi": 0.8686730265617371,
      "step": 720
    },
    {
      "epoch": 2.2934609250398723,
      "loss_nll": 0.14205169677734375,
      "loss_phi": 0.8935347199440002,
      "step": 720
    },
    {
      "epoch": 2.325358851674641,
      "grad_norm": 0.1310240775346756,
      "learning_rate": 4.522292993630574e-05,
      "loss": 0.159,
      "step": 730
    },
    {
      "epoch": 2.325358851674641,
      "loss_nll": 0.18197843432426453,
      "loss_phi": 0.8744394183158875,
      "step": 730
    },
    {
      "epoch": 2.325358851674641,
      "loss_nll": 0.1577443778514862,
      "loss_phi": 0.8793893456459045,
      "step": 730
    },
    {
      "epoch": 2.35725677830941,
      "grad_norm": 0.12958848476409912,
      "learning_rate": 4.309978768577495e-05,
      "loss": 0.1687,
      "step": 740
    },
    {
      "epoch": 2.35725677830941,
      "loss_nll": 0.12791606783866882,
      "loss_phi": 0.9110056161880493,
      "step": 740
    },
    {
      "epoch": 2.35725677830941,
      "loss_nll": 0.13391350209712982,
      "loss_phi": 0.9010427594184875,
      "step": 740
    },
    {
      "epoch": 2.3891547049441786,
      "grad_norm": 0.09387906640768051,
      "learning_rate": 4.0976645435244166e-05,
      "loss": 0.1548,
      "step": 750
    },
    {
      "epoch": 2.3891547049441786,
      "loss_nll": 0.24885877966880798,
      "loss_phi": 0.8785719275474548,
      "step": 750
    },
    {
      "epoch": 2.3891547049441786,
      "loss_nll": 0.11080354452133179,
      "loss_phi": 0.908393919467926,
      "step": 750
    },
    {
      "epoch": 2.4210526315789473,
      "grad_norm": 0.11650869995355606,
      "learning_rate": 3.885350318471338e-05,
      "loss": 0.1662,
      "step": 760
    },
    {
      "epoch": 2.4210526315789473,
      "loss_nll": 0.11803309619426727,
      "loss_phi": 0.9182068109512329,
      "step": 760
    },
    {
      "epoch": 2.4210526315789473,
      "loss_nll": 0.4762580394744873,
      "loss_phi": 0.878307580947876,
      "step": 760
    },
    {
      "epoch": 2.452950558213716,
      "grad_norm": 0.12620089948177338,
      "learning_rate": 3.673036093418259e-05,
      "loss": 0.1614,
      "step": 770
    },
    {
      "epoch": 2.452950558213716,
      "loss_nll": 0.27355942130088806,
      "loss_phi": 0.8803209662437439,
      "step": 770
    },
    {
      "epoch": 2.452950558213716,
      "loss_nll": 0.1229991540312767,
      "loss_phi": 0.9072089791297913,
      "step": 770
    },
    {
      "epoch": 2.484848484848485,
      "grad_norm": 0.24808214604854584,
      "learning_rate": 3.4607218683651803e-05,
      "loss": 0.2836,
      "step": 780
    },
    {
      "epoch": 2.484848484848485,
      "loss_nll": 0.23004044592380524,
      "loss_phi": 0.8800702691078186,
      "step": 780
    },
    {
      "epoch": 2.484848484848485,
      "loss_nll": 0.20113065838813782,
      "loss_phi": 0.8873058557510376,
      "step": 780
    },
    {
      "epoch": 2.5167464114832536,
      "grad_norm": 0.1562870889902115,
      "learning_rate": 3.248407643312102e-05,
      "loss": 0.1486,
      "step": 790
    },
    {
      "epoch": 2.5167464114832536,
      "loss_nll": 0.3097750246524811,
      "loss_phi": 0.883701741695404,
      "step": 790
    },
    {
      "epoch": 2.5167464114832536,
      "loss_nll": 0.07134898751974106,
      "loss_phi": 0.9081133604049683,
      "step": 790
    },
    {
      "epoch": 2.5486443381180224,
      "grad_norm": 0.12058036029338837,
      "learning_rate": 3.0360934182590233e-05,
      "loss": 0.178,
      "step": 800
    },
    {
      "epoch": 2.5486443381180224,
      "loss_nll": 0.28689849376678467,
      "loss_phi": 0.8681157231330872,
      "step": 800
    },
    {
      "epoch": 2.5486443381180224,
      "loss_nll": 0.261841356754303,
      "loss_phi": 0.8801130652427673,
      "step": 800
    },
    {
      "epoch": 2.580542264752791,
      "grad_norm": 0.13804775476455688,
      "learning_rate": 2.8237791932059447e-05,
      "loss": 0.1633,
      "step": 810
    },
    {
      "epoch": 2.580542264752791,
      "loss_nll": 0.07904481142759323,
      "loss_phi": 0.9188308119773865,
      "step": 810
    },
    {
      "epoch": 2.580542264752791,
      "loss_nll": 0.24299076199531555,
      "loss_phi": 0.8682970404624939,
      "step": 810
    },
    {
      "epoch": 2.61244019138756,
      "grad_norm": 0.12385524064302444,
      "learning_rate": 2.6114649681528662e-05,
      "loss": 0.1549,
      "step": 820
    },
    {
      "epoch": 2.61244019138756,
      "loss_nll": 0.27141836285591125,
      "loss_phi": 0.8815933465957642,
      "step": 820
    },
    {
      "epoch": 2.61244019138756,
      "loss_nll": 0.07914447039365768,
      "loss_phi": 0.910827100276947,
      "step": 820
    },
    {
      "epoch": 2.6443381180223287,
      "grad_norm": 0.10058949887752533,
      "learning_rate": 2.3991507430997877e-05,
      "loss": 0.148,
      "step": 830
    },
    {
      "epoch": 2.6443381180223287,
      "loss_nll": 0.13821059465408325,
      "loss_phi": 0.8924204111099243,
      "step": 830
    },
    {
      "epoch": 2.6443381180223287,
      "loss_nll": 0.34208598732948303,
      "loss_phi": 0.8603609204292297,
      "step": 830
    },
    {
      "epoch": 2.6762360446570974,
      "grad_norm": 0.12499668449163437,
      "learning_rate": 2.1868365180467095e-05,
      "loss": 0.1949,
      "step": 840
    },
    {
      "epoch": 2.6762360446570974,
      "loss_nll": 0.10973993688821793,
      "loss_phi": 0.8983036875724792,
      "step": 840
    },
    {
      "epoch": 2.6762360446570974,
      "loss_nll": 0.090643510222435,
      "loss_phi": 0.9040287137031555,
      "step": 840
    },
    {
      "epoch": 2.708133971291866,
      "grad_norm": 0.1298964023590088,
      "learning_rate": 1.974522292993631e-05,
      "loss": 0.1668,
      "step": 850
    },
    {
      "epoch": 2.708133971291866,
      "loss_nll": 0.6253595352172852,
      "loss_phi": 0.845397412776947,
      "step": 850
    },
    {
      "epoch": 2.708133971291866,
      "loss_nll": 0.3409216105937958,
      "loss_phi": 0.841521680355072,
      "step": 850
    },
    {
      "epoch": 2.740031897926635,
      "grad_norm": 0.13392339646816254,
      "learning_rate": 1.762208067940552e-05,
      "loss": 0.2062,
      "step": 860
    },
    {
      "epoch": 2.740031897926635,
      "loss_nll": 0.22156012058258057,
      "loss_phi": 0.8791170716285706,
      "step": 860
    },
    {
      "epoch": 2.740031897926635,
      "loss_nll": 0.1321578025817871,
      "loss_phi": 0.8848080039024353,
      "step": 860
    },
    {
      "epoch": 2.7719298245614032,
      "grad_norm": 0.1340840607881546,
      "learning_rate": 1.5498938428874735e-05,
      "loss": 0.1803,
      "step": 870
    },
    {
      "epoch": 2.7719298245614032,
      "loss_nll": 0.16270530223846436,
      "loss_phi": 0.8839789032936096,
      "step": 870
    },
    {
      "epoch": 2.7719298245614032,
      "loss_nll": 0.16090738773345947,
      "loss_phi": 0.8969550728797913,
      "step": 870
    },
    {
      "epoch": 2.803827751196172,
      "grad_norm": 0.11204183101654053,
      "learning_rate": 1.337579617834395e-05,
      "loss": 0.1716,
      "step": 880
    },
    {
      "epoch": 2.803827751196172,
      "loss_nll": 0.1907777190208435,
      "loss_phi": 0.8922702670097351,
      "step": 880
    },
    {
      "epoch": 2.803827751196172,
      "loss_nll": 0.3885509967803955,
      "loss_phi": 0.8640924692153931,
      "step": 880
    },
    {
      "epoch": 2.8357256778309408,
      "grad_norm": 0.1362811028957367,
      "learning_rate": 1.1252653927813164e-05,
      "loss": 0.1753,
      "step": 890
    },
    {
      "epoch": 2.8357256778309408,
      "loss_nll": 0.21588079631328583,
      "loss_phi": 0.8677371740341187,
      "step": 890
    },
    {
      "epoch": 2.8357256778309408,
      "loss_nll": 0.10012825578451157,
      "loss_phi": 0.8791846632957458,
      "step": 890
    },
    {
      "epoch": 2.8676236044657095,
      "grad_norm": 0.1465572863817215,
      "learning_rate": 9.129511677282377e-06,
      "loss": 0.2301,
      "step": 900
    },
    {
      "epoch": 2.8676236044657095,
      "loss_nll": 0.14566783607006073,
      "loss_phi": 0.8849511742591858,
      "step": 900
    },
    {
      "epoch": 2.8676236044657095,
      "loss_nll": 0.19855113327503204,
      "loss_phi": 0.8878235220909119,
      "step": 900
    },
    {
      "epoch": 2.8995215311004783,
      "grad_norm": 0.2170732319355011,
      "learning_rate": 7.006369426751593e-06,
      "loss": 0.2174,
      "step": 910
    },
    {
      "epoch": 2.8995215311004783,
      "loss_nll": 0.16603446006774902,
      "loss_phi": 0.8793769478797913,
      "step": 910
    },
    {
      "epoch": 2.8995215311004783,
      "loss_nll": 0.17126530408859253,
      "loss_phi": 0.8983373045921326,
      "step": 910
    },
    {
      "epoch": 2.931419457735247,
      "grad_norm": 0.15170565247535706,
      "learning_rate": 4.8832271762208075e-06,
      "loss": 0.1697,
      "step": 920
    },
    {
      "epoch": 2.931419457735247,
      "loss_nll": 0.17709389328956604,
      "loss_phi": 0.8811878561973572,
      "step": 920
    },
    {
      "epoch": 2.931419457735247,
      "loss_nll": 0.05407186597585678,
      "loss_phi": 0.9148798584938049,
      "step": 920
    },
    {
      "epoch": 2.963317384370016,
      "grad_norm": 0.1470419466495514,
      "learning_rate": 2.7600849256900213e-06,
      "loss": 0.1828,
      "step": 930
    },
    {
      "epoch": 2.963317384370016,
      "loss_nll": 0.1894863247871399,
      "loss_phi": 0.8795869946479797,
      "step": 930
    },
    {
      "epoch": 2.963317384370016,
      "loss_nll": 0.23718687891960144,
      "loss_phi": 0.8729574084281921,
      "step": 930
    },
    {
      "epoch": 2.9952153110047846,
      "grad_norm": 0.10731732100248337,
      "learning_rate": 6.369426751592357e-07,
      "loss": 0.1702,
      "step": 940
    },
    {
      "epoch": 2.9952153110047846,
      "loss_nll": 0.0741524025797844,
      "loss_phi": 0.8995509743690491,
      "step": 940
    },
    {
      "epoch": 2.9952153110047846,
      "loss_nll": 0.12066208571195602,
      "loss_phi": 0.8979397416114807,
      "step": 940
    }
  ],
  "logging_steps": 10,
  "max_steps": 942,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.396350846284595e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
