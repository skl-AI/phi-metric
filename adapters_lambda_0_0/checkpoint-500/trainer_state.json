{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.5933014354066986,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0,
      "loss_nll": 10.808700561523438,
      "loss_phi": 0.6487162113189697,
      "step": 0
    },
    {
      "epoch": 0,
      "loss_nll": 10.742116928100586,
      "loss_phi": 0.6627302169799805,
      "step": 0
    },
    {
      "epoch": 0.03189792663476874,
      "grad_norm": 28.08063507080078,
      "learning_rate": 0.0001980891719745223,
      "loss": 9.4666,
      "step": 10
    },
    {
      "epoch": 0.03189792663476874,
      "loss_nll": 2.720599889755249,
      "loss_phi": 1.37460458278656,
      "step": 10
    },
    {
      "epoch": 0.03189792663476874,
      "loss_nll": 2.5038537979125977,
      "loss_phi": 1.436585545539856,
      "step": 10
    },
    {
      "epoch": 0.06379585326953748,
      "grad_norm": 0.194207102060318,
      "learning_rate": 0.00019596602972399152,
      "loss": 0.7952,
      "step": 20
    },
    {
      "epoch": 0.06379585326953748,
      "loss_nll": 0.1514761745929718,
      "loss_phi": 0.7572923898696899,
      "step": 20
    },
    {
      "epoch": 0.06379585326953748,
      "loss_nll": 0.42479783296585083,
      "loss_phi": 0.7209903597831726,
      "step": 20
    },
    {
      "epoch": 0.09569377990430622,
      "grad_norm": 0.26362305879592896,
      "learning_rate": 0.00019384288747346072,
      "loss": 0.2321,
      "step": 30
    },
    {
      "epoch": 0.09569377990430622,
      "loss_nll": 0.16743141412734985,
      "loss_phi": 0.787182092666626,
      "step": 30
    },
    {
      "epoch": 0.09569377990430622,
      "loss_nll": 0.13785694539546967,
      "loss_phi": 0.8030600547790527,
      "step": 30
    },
    {
      "epoch": 0.12759170653907495,
      "grad_norm": 0.1562580168247223,
      "learning_rate": 0.00019171974522292994,
      "loss": 0.2097,
      "step": 40
    },
    {
      "epoch": 0.12759170653907495,
      "loss_nll": 0.3858400583267212,
      "loss_phi": 0.7640789151191711,
      "step": 40
    },
    {
      "epoch": 0.12759170653907495,
      "loss_nll": 0.1498568058013916,
      "loss_phi": 0.7695814967155457,
      "step": 40
    },
    {
      "epoch": 0.1594896331738437,
      "grad_norm": 0.14562377333641052,
      "learning_rate": 0.00018959660297239916,
      "loss": 0.2,
      "step": 50
    },
    {
      "epoch": 0.1594896331738437,
      "loss_nll": 0.3179241716861725,
      "loss_phi": 0.7390020489692688,
      "step": 50
    },
    {
      "epoch": 0.1594896331738437,
      "loss_nll": 0.1866222321987152,
      "loss_phi": 0.7658565044403076,
      "step": 50
    },
    {
      "epoch": 0.19138755980861244,
      "grad_norm": 0.12827306985855103,
      "learning_rate": 0.00018747346072186838,
      "loss": 0.1787,
      "step": 60
    },
    {
      "epoch": 0.19138755980861244,
      "loss_nll": 0.4467284679412842,
      "loss_phi": 0.715237021446228,
      "step": 60
    },
    {
      "epoch": 0.19138755980861244,
      "loss_nll": 0.19801530241966248,
      "loss_phi": 0.7420855164527893,
      "step": 60
    },
    {
      "epoch": 0.22328548644338117,
      "grad_norm": 0.12065152078866959,
      "learning_rate": 0.0001853503184713376,
      "loss": 0.2466,
      "step": 70
    },
    {
      "epoch": 0.22328548644338117,
      "loss_nll": 0.17285336554050446,
      "loss_phi": 0.7308071255683899,
      "step": 70
    },
    {
      "epoch": 0.22328548644338117,
      "loss_nll": 1.3103289604187012,
      "loss_phi": 0.6637372970581055,
      "step": 70
    },
    {
      "epoch": 0.2551834130781499,
      "grad_norm": 0.178571879863739,
      "learning_rate": 0.0001832271762208068,
      "loss": 0.2748,
      "step": 80
    },
    {
      "epoch": 0.2551834130781499,
      "loss_nll": 0.25496676564216614,
      "loss_phi": 0.7395704984664917,
      "step": 80
    },
    {
      "epoch": 0.2551834130781499,
      "loss_nll": 0.17823021113872528,
      "loss_phi": 0.746060311794281,
      "step": 80
    },
    {
      "epoch": 0.28708133971291866,
      "grad_norm": 0.16763338446617126,
      "learning_rate": 0.00018110403397027602,
      "loss": 0.1762,
      "step": 90
    },
    {
      "epoch": 0.28708133971291866,
      "loss_nll": 0.21845662593841553,
      "loss_phi": 0.7334336042404175,
      "step": 90
    },
    {
      "epoch": 0.28708133971291866,
      "loss_nll": 0.326570063829422,
      "loss_phi": 0.767210841178894,
      "step": 90
    },
    {
      "epoch": 0.3189792663476874,
      "grad_norm": 0.17228879034519196,
      "learning_rate": 0.00017898089171974524,
      "loss": 0.1885,
      "step": 100
    },
    {
      "epoch": 0.3189792663476874,
      "loss_nll": 0.617048442363739,
      "loss_phi": 0.7698190212249756,
      "step": 100
    },
    {
      "epoch": 0.3189792663476874,
      "loss_nll": 0.23909372091293335,
      "loss_phi": 0.7762323617935181,
      "step": 100
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.08443082123994827,
      "learning_rate": 0.00017685774946921446,
      "loss": 0.1605,
      "step": 110
    },
    {
      "epoch": 0.3508771929824561,
      "loss_nll": 0.10018111765384674,
      "loss_phi": 0.8063313961029053,
      "step": 110
    },
    {
      "epoch": 0.3508771929824561,
      "loss_nll": 0.08156679570674896,
      "loss_phi": 0.8220557570457458,
      "step": 110
    },
    {
      "epoch": 0.3827751196172249,
      "grad_norm": 0.10031794756650925,
      "learning_rate": 0.00017473460721868366,
      "loss": 0.1986,
      "step": 120
    },
    {
      "epoch": 0.3827751196172249,
      "loss_nll": 0.21857453882694244,
      "loss_phi": 0.7862492203712463,
      "step": 120
    },
    {
      "epoch": 0.3827751196172249,
      "loss_nll": 0.12961649894714355,
      "loss_phi": 0.8087995648384094,
      "step": 120
    },
    {
      "epoch": 0.41467304625199364,
      "grad_norm": 0.09967644512653351,
      "learning_rate": 0.00017261146496815288,
      "loss": 0.1783,
      "step": 130
    },
    {
      "epoch": 0.41467304625199364,
      "loss_nll": 0.2455701380968094,
      "loss_phi": 0.7806245684623718,
      "step": 130
    },
    {
      "epoch": 0.41467304625199364,
      "loss_nll": 0.0974080041050911,
      "loss_phi": 0.8096339106559753,
      "step": 130
    },
    {
      "epoch": 0.44657097288676234,
      "grad_norm": 0.11234539747238159,
      "learning_rate": 0.0001704883227176221,
      "loss": 0.1956,
      "step": 140
    },
    {
      "epoch": 0.44657097288676234,
      "loss_nll": 0.10664516687393188,
      "loss_phi": 0.8200146555900574,
      "step": 140
    },
    {
      "epoch": 0.44657097288676234,
      "loss_nll": 0.24267996847629547,
      "loss_phi": 0.7875090837478638,
      "step": 140
    },
    {
      "epoch": 0.4784688995215311,
      "grad_norm": 0.1168106198310852,
      "learning_rate": 0.00016836518046709132,
      "loss": 0.2041,
      "step": 150
    },
    {
      "epoch": 0.4784688995215311,
      "loss_nll": 0.13609878718852997,
      "loss_phi": 0.8296263217926025,
      "step": 150
    },
    {
      "epoch": 0.4784688995215311,
      "loss_nll": 0.2965090274810791,
      "loss_phi": 0.8145728707313538,
      "step": 150
    },
    {
      "epoch": 0.5103668261562998,
      "grad_norm": 0.11596345156431198,
      "learning_rate": 0.00016624203821656052,
      "loss": 0.1868,
      "step": 160
    },
    {
      "epoch": 0.5103668261562998,
      "loss_nll": 0.1254463940858841,
      "loss_phi": 0.8481245040893555,
      "step": 160
    },
    {
      "epoch": 0.5103668261562998,
      "loss_nll": 0.2105049192905426,
      "loss_phi": 0.8366210460662842,
      "step": 160
    },
    {
      "epoch": 0.5422647527910686,
      "grad_norm": 0.22156290709972382,
      "learning_rate": 0.00016411889596602974,
      "loss": 0.1527,
      "step": 170
    },
    {
      "epoch": 0.5422647527910686,
      "loss_nll": 0.2798381745815277,
      "loss_phi": 0.8254292607307434,
      "step": 170
    },
    {
      "epoch": 0.5422647527910686,
      "loss_nll": 0.17082232236862183,
      "loss_phi": 0.8455524444580078,
      "step": 170
    },
    {
      "epoch": 0.5741626794258373,
      "grad_norm": 0.09991440176963806,
      "learning_rate": 0.00016199575371549896,
      "loss": 0.1825,
      "step": 180
    },
    {
      "epoch": 0.5741626794258373,
      "loss_nll": 0.12219855189323425,
      "loss_phi": 0.8368667960166931,
      "step": 180
    },
    {
      "epoch": 0.5741626794258373,
      "loss_nll": 0.15032678842544556,
      "loss_phi": 0.8305685520172119,
      "step": 180
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 0.2664113938808441,
      "learning_rate": 0.00015987261146496818,
      "loss": 0.1927,
      "step": 190
    },
    {
      "epoch": 0.6060606060606061,
      "loss_nll": 0.17942717671394348,
      "loss_phi": 0.8508134484291077,
      "step": 190
    },
    {
      "epoch": 0.6060606060606061,
      "loss_nll": 0.7520633339881897,
      "loss_phi": 0.7671253681182861,
      "step": 190
    },
    {
      "epoch": 0.6379585326953748,
      "grad_norm": 0.0906132310628891,
      "learning_rate": 0.00015774946921443737,
      "loss": 0.1941,
      "step": 200
    },
    {
      "epoch": 0.6379585326953748,
      "loss_nll": 0.17645490169525146,
      "loss_phi": 0.8451724648475647,
      "step": 200
    },
    {
      "epoch": 0.6379585326953748,
      "loss_nll": 0.13028742372989655,
      "loss_phi": 0.8514065146446228,
      "step": 200
    },
    {
      "epoch": 0.6698564593301436,
      "grad_norm": 0.2470761090517044,
      "learning_rate": 0.0001556263269639066,
      "loss": 0.1928,
      "step": 210
    },
    {
      "epoch": 0.6698564593301436,
      "loss_nll": 0.2273246794939041,
      "loss_phi": 0.8662674427032471,
      "step": 210
    },
    {
      "epoch": 0.6698564593301436,
      "loss_nll": 0.060652345418930054,
      "loss_phi": 0.857589840888977,
      "step": 210
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.13569119572639465,
      "learning_rate": 0.00015350318471337582,
      "loss": 0.1843,
      "step": 220
    },
    {
      "epoch": 0.7017543859649122,
      "loss_nll": 0.18647103011608124,
      "loss_phi": 0.8614968657493591,
      "step": 220
    },
    {
      "epoch": 0.7017543859649122,
      "loss_nll": 0.7360398173332214,
      "loss_phi": 0.79609215259552,
      "step": 220
    },
    {
      "epoch": 0.733652312599681,
      "grad_norm": 0.1439184993505478,
      "learning_rate": 0.00015138004246284504,
      "loss": 0.255,
      "step": 230
    },
    {
      "epoch": 0.733652312599681,
      "loss_nll": 0.1495232880115509,
      "loss_phi": 0.8689184188842773,
      "step": 230
    },
    {
      "epoch": 0.733652312599681,
      "loss_nll": 0.10720354318618774,
      "loss_phi": 0.874816358089447,
      "step": 230
    },
    {
      "epoch": 0.7655502392344498,
      "grad_norm": 0.14538688957691193,
      "learning_rate": 0.00014925690021231423,
      "loss": 0.1782,
      "step": 240
    },
    {
      "epoch": 0.7655502392344498,
      "loss_nll": 0.14682988822460175,
      "loss_phi": 0.8947947025299072,
      "step": 240
    },
    {
      "epoch": 0.7655502392344498,
      "loss_nll": 0.11227154731750488,
      "loss_phi": 0.9001619815826416,
      "step": 240
    },
    {
      "epoch": 0.7974481658692185,
      "grad_norm": 0.13068340718746185,
      "learning_rate": 0.00014713375796178343,
      "loss": 0.1596,
      "step": 250
    },
    {
      "epoch": 0.7974481658692185,
      "loss_nll": 0.20835067331790924,
      "loss_phi": 0.8921992182731628,
      "step": 250
    },
    {
      "epoch": 0.7974481658692185,
      "loss_nll": 0.16937196254730225,
      "loss_phi": 0.9101194143295288,
      "step": 250
    },
    {
      "epoch": 0.8293460925039873,
      "grad_norm": 0.11087094247341156,
      "learning_rate": 0.00014501061571125265,
      "loss": 0.2332,
      "step": 260
    },
    {
      "epoch": 0.8293460925039873,
      "loss_nll": 0.08658458292484283,
      "loss_phi": 0.9115540981292725,
      "step": 260
    },
    {
      "epoch": 0.8293460925039873,
      "loss_nll": 0.4286443591117859,
      "loss_phi": 0.8513653874397278,
      "step": 260
    },
    {
      "epoch": 0.861244019138756,
      "grad_norm": 0.10842572897672653,
      "learning_rate": 0.00014288747346072187,
      "loss": 0.2002,
      "step": 270
    },
    {
      "epoch": 0.861244019138756,
      "loss_nll": 0.12277328968048096,
      "loss_phi": 0.9113991856575012,
      "step": 270
    },
    {
      "epoch": 0.861244019138756,
      "loss_nll": 0.06710612028837204,
      "loss_phi": 0.9205551743507385,
      "step": 270
    },
    {
      "epoch": 0.8931419457735247,
      "grad_norm": 0.09004785120487213,
      "learning_rate": 0.0001407643312101911,
      "loss": 0.1883,
      "step": 280
    },
    {
      "epoch": 0.8931419457735247,
      "loss_nll": 0.15219806134700775,
      "loss_phi": 0.9104117155075073,
      "step": 280
    },
    {
      "epoch": 0.8931419457735247,
      "loss_nll": 0.08298785239458084,
      "loss_phi": 0.9419856071472168,
      "step": 280
    },
    {
      "epoch": 0.9250398724082934,
      "grad_norm": 0.16891537606716156,
      "learning_rate": 0.00013864118895966029,
      "loss": 0.1922,
      "step": 290
    },
    {
      "epoch": 0.9250398724082934,
      "loss_nll": 0.0669475793838501,
      "loss_phi": 0.958117663860321,
      "step": 290
    },
    {
      "epoch": 0.9250398724082934,
      "loss_nll": 1.0359065532684326,
      "loss_phi": 0.8099314570426941,
      "step": 290
    },
    {
      "epoch": 0.9569377990430622,
      "grad_norm": 0.0813242718577385,
      "learning_rate": 0.0001365180467091295,
      "loss": 0.2079,
      "step": 300
    },
    {
      "epoch": 0.9569377990430622,
      "loss_nll": 0.07846184819936752,
      "loss_phi": 0.9125208854675293,
      "step": 300
    },
    {
      "epoch": 0.9569377990430622,
      "loss_nll": 0.1357584148645401,
      "loss_phi": 0.8847312331199646,
      "step": 300
    },
    {
      "epoch": 0.988835725677831,
      "grad_norm": 0.15659628808498383,
      "learning_rate": 0.00013439490445859873,
      "loss": 0.1689,
      "step": 310
    },
    {
      "epoch": 0.988835725677831,
      "loss_nll": 0.4542628228664398,
      "loss_phi": 0.8755845427513123,
      "step": 310
    },
    {
      "epoch": 0.988835725677831,
      "loss_nll": 0.1432798206806183,
      "loss_phi": 0.892400860786438,
      "step": 310
    },
    {
      "epoch": 1.0191387559808613,
      "grad_norm": 0.09681388735771179,
      "learning_rate": 0.00013227176220806795,
      "loss": 0.2432,
      "step": 320
    },
    {
      "epoch": 1.0191387559808613,
      "loss_nll": 0.17207130789756775,
      "loss_phi": 0.866628110408783,
      "step": 320
    },
    {
      "epoch": 1.0191387559808613,
      "loss_nll": 0.21370188891887665,
      "loss_phi": 0.8843221664428711,
      "step": 320
    },
    {
      "epoch": 1.0510366826156299,
      "grad_norm": 0.14774389564990997,
      "learning_rate": 0.00013014861995753714,
      "loss": 0.2043,
      "step": 330
    },
    {
      "epoch": 1.0510366826156299,
      "loss_nll": 0.24537459015846252,
      "loss_phi": 0.8724808096885681,
      "step": 330
    },
    {
      "epoch": 1.0510366826156299,
      "loss_nll": 0.07879865914583206,
      "loss_phi": 0.9131184220314026,
      "step": 330
    },
    {
      "epoch": 1.0829346092503986,
      "grad_norm": 0.1276455670595169,
      "learning_rate": 0.00012802547770700637,
      "loss": 0.1602,
      "step": 340
    },
    {
      "epoch": 1.0829346092503986,
      "loss_nll": 0.17920450866222382,
      "loss_phi": 0.8708730340003967,
      "step": 340
    },
    {
      "epoch": 1.0829346092503986,
      "loss_nll": 0.08992837369441986,
      "loss_phi": 0.9244045615196228,
      "step": 340
    },
    {
      "epoch": 1.1148325358851674,
      "grad_norm": 0.1270705908536911,
      "learning_rate": 0.0001259023354564756,
      "loss": 0.1839,
      "step": 350
    },
    {
      "epoch": 1.1148325358851674,
      "loss_nll": 0.21000969409942627,
      "loss_phi": 0.8863369822502136,
      "step": 350
    },
    {
      "epoch": 1.1148325358851674,
      "loss_nll": 0.1376953125,
      "loss_phi": 0.8995702862739563,
      "step": 350
    },
    {
      "epoch": 1.1467304625199362,
      "grad_norm": 0.10082706809043884,
      "learning_rate": 0.0001237791932059448,
      "loss": 0.206,
      "step": 360
    },
    {
      "epoch": 1.1467304625199362,
      "loss_nll": 0.11698930710554123,
      "loss_phi": 0.9235067963600159,
      "step": 360
    },
    {
      "epoch": 1.1467304625199362,
      "loss_nll": 0.12434802204370499,
      "loss_phi": 0.9165676236152649,
      "step": 360
    },
    {
      "epoch": 1.178628389154705,
      "grad_norm": 0.10052314400672913,
      "learning_rate": 0.00012165605095541402,
      "loss": 0.1821,
      "step": 370
    },
    {
      "epoch": 1.178628389154705,
      "loss_nll": 0.30320388078689575,
      "loss_phi": 0.8635985851287842,
      "step": 370
    },
    {
      "epoch": 1.178628389154705,
      "loss_nll": 0.087426096200943,
      "loss_phi": 0.9195497035980225,
      "step": 370
    },
    {
      "epoch": 1.2105263157894737,
      "grad_norm": 0.086951844394207,
      "learning_rate": 0.00011953290870488322,
      "loss": 0.2163,
      "step": 380
    },
    {
      "epoch": 1.2105263157894737,
      "loss_nll": 0.190107524394989,
      "loss_phi": 0.8757569193840027,
      "step": 380
    },
    {
      "epoch": 1.2105263157894737,
      "loss_nll": 0.3288576900959015,
      "loss_phi": 0.8490412831306458,
      "step": 380
    },
    {
      "epoch": 1.2424242424242424,
      "grad_norm": 0.10947724431753159,
      "learning_rate": 0.00011740976645435245,
      "loss": 0.1879,
      "step": 390
    },
    {
      "epoch": 1.2424242424242424,
      "loss_nll": 0.09728062152862549,
      "loss_phi": 0.9298111200332642,
      "step": 390
    },
    {
      "epoch": 1.2424242424242424,
      "loss_nll": 0.0791739895939827,
      "loss_phi": 0.9070656895637512,
      "step": 390
    },
    {
      "epoch": 1.2743221690590112,
      "grad_norm": 0.19410553574562073,
      "learning_rate": 0.00011528662420382165,
      "loss": 0.2442,
      "step": 400
    },
    {
      "epoch": 1.2743221690590112,
      "loss_nll": 0.24545074999332428,
      "loss_phi": 0.8589752912521362,
      "step": 400
    },
    {
      "epoch": 1.2743221690590112,
      "loss_nll": 0.10856705158948898,
      "loss_phi": 0.9098759293556213,
      "step": 400
    },
    {
      "epoch": 1.30622009569378,
      "grad_norm": 0.12012659013271332,
      "learning_rate": 0.00011316348195329088,
      "loss": 0.1818,
      "step": 410
    },
    {
      "epoch": 1.30622009569378,
      "loss_nll": 0.6970430612564087,
      "loss_phi": 0.850292444229126,
      "step": 410
    },
    {
      "epoch": 1.30622009569378,
      "loss_nll": 0.7490484118461609,
      "loss_phi": 0.855429470539093,
      "step": 410
    },
    {
      "epoch": 1.3381180223285487,
      "grad_norm": 0.13530313968658447,
      "learning_rate": 0.00011104033970276008,
      "loss": 0.2358,
      "step": 420
    },
    {
      "epoch": 1.3381180223285487,
      "loss_nll": 0.13984344899654388,
      "loss_phi": 0.8798052668571472,
      "step": 420
    },
    {
      "epoch": 1.3381180223285487,
      "loss_nll": 0.26350536942481995,
      "loss_phi": 0.8927325010299683,
      "step": 420
    },
    {
      "epoch": 1.3700159489633175,
      "grad_norm": 0.12002824246883392,
      "learning_rate": 0.0001089171974522293,
      "loss": 0.1526,
      "step": 430
    },
    {
      "epoch": 1.3700159489633175,
      "loss_nll": 0.08920230716466904,
      "loss_phi": 0.8889291882514954,
      "step": 430
    },
    {
      "epoch": 1.3700159489633175,
      "loss_nll": 0.11580220609903336,
      "loss_phi": 0.8810025453567505,
      "step": 430
    },
    {
      "epoch": 1.401913875598086,
      "grad_norm": 0.09595569968223572,
      "learning_rate": 0.00010679405520169851,
      "loss": 0.1528,
      "step": 440
    },
    {
      "epoch": 1.401913875598086,
      "loss_nll": 0.3028004467487335,
      "loss_phi": 0.8644437193870544,
      "step": 440
    },
    {
      "epoch": 1.401913875598086,
      "loss_nll": 0.1618187427520752,
      "loss_phi": 0.888277530670166,
      "step": 440
    },
    {
      "epoch": 1.4338118022328548,
      "grad_norm": 0.11820270121097565,
      "learning_rate": 0.00010467091295116773,
      "loss": 0.1541,
      "step": 450
    },
    {
      "epoch": 1.4338118022328548,
      "loss_nll": 0.1128934696316719,
      "loss_phi": 0.9025892615318298,
      "step": 450
    },
    {
      "epoch": 1.4338118022328548,
      "loss_nll": 0.08102896809577942,
      "loss_phi": 0.9046285152435303,
      "step": 450
    },
    {
      "epoch": 1.4657097288676235,
      "grad_norm": 0.23637047410011292,
      "learning_rate": 0.00010254777070063694,
      "loss": 0.1945,
      "step": 460
    },
    {
      "epoch": 1.4657097288676235,
      "loss_nll": 0.2621864974498749,
      "loss_phi": 0.8750171661376953,
      "step": 460
    },
    {
      "epoch": 1.4657097288676235,
      "loss_nll": 0.14026691019535065,
      "loss_phi": 0.9197640419006348,
      "step": 460
    },
    {
      "epoch": 1.4976076555023923,
      "grad_norm": 0.14527903497219086,
      "learning_rate": 0.00010042462845010616,
      "loss": 0.2478,
      "step": 470
    },
    {
      "epoch": 1.4976076555023923,
      "loss_nll": 0.23326976597309113,
      "loss_phi": 0.9025905728340149,
      "step": 470
    },
    {
      "epoch": 1.4976076555023923,
      "loss_nll": 0.09685070067644119,
      "loss_phi": 0.9217519164085388,
      "step": 470
    },
    {
      "epoch": 1.529505582137161,
      "grad_norm": 0.11758971959352493,
      "learning_rate": 9.830148619957537e-05,
      "loss": 0.1912,
      "step": 480
    },
    {
      "epoch": 1.529505582137161,
      "loss_nll": 0.11770422011613846,
      "loss_phi": 0.8983247876167297,
      "step": 480
    },
    {
      "epoch": 1.529505582137161,
      "loss_nll": 0.1540045440196991,
      "loss_phi": 0.8986915946006775,
      "step": 480
    },
    {
      "epoch": 1.5614035087719298,
      "grad_norm": 0.15657232701778412,
      "learning_rate": 9.617834394904459e-05,
      "loss": 0.1753,
      "step": 490
    },
    {
      "epoch": 1.5614035087719298,
      "loss_nll": 0.08652830123901367,
      "loss_phi": 0.9125277400016785,
      "step": 490
    },
    {
      "epoch": 1.5614035087719298,
      "loss_nll": 0.2346920371055603,
      "loss_phi": 0.8859001994132996,
      "step": 490
    },
    {
      "epoch": 1.5933014354066986,
      "grad_norm": 0.11748173087835312,
      "learning_rate": 9.40552016985138e-05,
      "loss": 0.1508,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 942,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2727030810411008e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
